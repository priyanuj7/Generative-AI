{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b20efc-5deb-46f0-ad66-5efe40e8187a",
   "metadata": {},
   "source": [
    "### Document Chains\n",
    "\n",
    "#### Document chains allows to process and analyse large amounts of text data efficiently. They provide a structured approach to  working with documents, enabling one to retrieve, filter, and rank them based on specific criteria\n",
    "\n",
    "#### By using different types of Document Chains like Stuff, Refine, Map Reduce, Map Re-rank, you can perform specific operations on the retrieved documents and obtain more accurate and relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740223b8-bd94-4e3e-90f9-c32d19fd608e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import textwrap\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a956b9-78f5-42af-8923-974708261b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(model_name = \"gpt-3.5-turbo-instruct\", temperature = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528bf331-ad06-466d-8a48-da0609a52c51",
   "metadata": {},
   "source": [
    "### Stuff Chain\n",
    "####\n",
    "#### This involve putting the entire information to the LLM at one go, i.e. putting all relevant data into the Prompt for LangChain's Stuff Documents Chain to Process. The advantage of this method is that it only requires one call to the LLM, and the model has access to all the information at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba3e8639-2322-4518-a36d-20dabf81d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Priyanuj_Misra_Resume_AI.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a47969-0746-43b8-9b25-eac9e39bd489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Document No:  1\n",
      "PriyanujMisra\n",
      "Senior Data Scientist\n",
      "Dubai,UAE\n",
      " GitHub\n",
      " LinkedIn\n",
      " priyanujmisra.nits@gmail.com\n",
      " +971506138031\n",
      "PROFESSIONALSUMMARY\n",
      "Senior Data Scientist with 5+ years of experience in leveraging Advanced Analytics and Artificial Intelligence to provide ac-\n",
      "tionable insights for Fortune 50 global leaders in BFSI, Retail and Telecom industries. Proficient in implementing end-to-end\n",
      "data modeling pipelines and solutions using Python, PySpark, and Driverless AI, with expertise in Machine Learning and Deep\n",
      "Learning algorithms.\n",
      "EXPERIENCE\n",
      "Etisalate&UAE | SENIOR DATA SCIENTIST\n",
      "Aug2024–Present|Dubai,UAE\n",
      "Ô Roles and Responsibilities - Part of the CVM Modeling team delivering Machine\n",
      "Learning and Generative AI solutions to optimize business needs and drive\n",
      "revenue. Currently working on preparing a SOP for Information Retrieval using Gen\n",
      "AI (LLM)\n",
      "Ô Customer Rejection Reason Analysis - Developed a Topic Modeling Pipeline\n",
      "using Latent Dirichlet Allocation (LDA) to systematically segment and analyze\n",
      "customer rejection reasons, providing actionable insights to enhance product\n",
      "offerings and reduce rejection rates\n",
      "WellsFargo | SENIOR DATA SCIENTIST\n",
      "June,2021–July,2024|Bangalore,India\n",
      "Ô Loan Approval Date Prediction and Task Prioritization - Developed and deployed\n",
      "a 5-model XGBoost Regression pipeline within the ModelOps framework,\n",
      "enhancing prediction accuracy for Home Lending loans while reducing cycle time\n",
      "by 18% and generating $3.5 million in operational savings\n",
      "Ô Causal Impact Analysis for Marketing Conversations - Led the development of a\n",
      "process utilizing Pyspark and H2O to assess the causality of Marketing\n",
      "Conversations on revenue targets, employing advanced methodologies like\n",
      "Coarsened Exact Matching to establish comparable groups. Utilized Meta\n",
      "Learners to derive ATT/ATEvalues, resulting in an annual profit value of $12.23\n",
      "per customer\n",
      "Ô Feature Tracker Automation - Developed a feature tracking pipeline to monitor\n",
      "3,000+ features weekly, generating ad-hoc summary reports with critical\n",
      "information including summary statistics and Population Stability Index (PSI)\n",
      "MuSigma | DATA SCIENTIST\n",
      "May,2019–June,2021|Bangalore,India\n",
      "Ô Propensity Modeling to enhance Customer Online Engagement - Engineered a\n",
      "Python-based propensity modeling pipeline with a RandomForest classifier to\n",
      "optimize online offers, achieving a fourfold improvement in redemption rate and\n",
      "accelerating customer engagement through seamless integration into the Offer\n",
      "Management system\n",
      "Ô Campaign Design and Management - Designed and implemented an automated\n",
      "capability system in Google BigQuery to distribute personalized offers to over 3\n",
      "Million loyalty customers, yielding pilot campaigns with a projected 30%\n",
      "incremental Year-over-Yearsign-ups and a 5-7% lift in loyalty customer sales\n",
      "Ô Marketing Campaign Measurement - Led the design and implementation of\n",
      "promotional campaigns for MVP experience offers post National Launch,\n",
      "conducting comprehensive Pre-Post analysis on Test and Control segments to\n",
      "optimize campaign effectiveness\n",
      "EDUCATION\n",
      "LIVERPOOLJOHNMOORES\n",
      "UNIVERSITY\n",
      "MS - Machine Learning and AI\n",
      "Aug 2024 - Present | Ongoing\n",
      "Upgrad(Online)\n",
      "NATIONALINSTITUTEOF\n",
      "TECHNOLOGYSILCHAR\n",
      "(NITS)\n",
      "B.Tech - Civil Engineering\n",
      "July, 2015 - May, 2019\n",
      "Silchar,Assam,India\n",
      "SKILLS\n",
      "PROGRAMMING|TOOLS\n",
      "• Python • SQL • Pyspark •\n",
      "Google Cloud Platform • Azure\n",
      "Databricks • GitHub • OSDS •\n",
      "H2O • Jupyter • DataRobot\n",
      "CORECOMPETENCIES\n",
      "• Machine Learning • Deep\n",
      "Learning • Classification •\n",
      "Regression • Random Forest •\n",
      "Boosting Algorithm • NLP •\n",
      "Transformers • Causal\n",
      "Inference • Word Embeddings\n",
      "• Large Language Models •\n",
      "Customer Analytics •\n",
      "Campaign Analytics •\n",
      "Generative AI • Langchain •\n",
      "A/B Testing • Hypothesis\n",
      "Testing • LlamaIndex\n",
      "RECOGNITION\n",
      "SPOTAWARD\n",
      "Citation - Created significant\n",
      "impact by building a propensity\n",
      "model for customer\n",
      "engagement which in turn\n",
      "improved redemption rate\n",
      "fourfold\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for doc in docs:\n",
    "    cnt+=1\n",
    "    print(\"------------Document No: \", cnt)\n",
    "    print(doc.page_content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf929349-6678-46be-901e-549d02ffbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    " You are given a Resume as the below text.\n",
    " ----\n",
    " {text}\n",
    " ----\n",
    " Question: Pleaes respond with the Key Skills and Experience summary of the person.\n",
    " Key Skills:\n",
    " Experience Summary:\n",
    " Note: Please put the key skills one by one in a separate line\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7277fe4-bc67-4537-8ced-05433ebd9209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key Skills:\n",
      "- Advanced Analytics\n",
      "- Artificial Intelligence\n",
      "- Python\n",
      "- PySpark\n",
      "- Driverless AI\n",
      "- Machine Learning\n",
      "- Deep Learning\n",
      "- Data Modeling\n",
      "- Data Pipelines\n",
      "- Customer Analytics\n",
      "- Campaign Analytics\n",
      "- Generative AI\n",
      "- Natural Language Processing (NLP)\n",
      "- Transformers\n",
      "- Causal Inference\n",
      "- Word Embeddings\n",
      "- Large Language Models\n",
      "- A/B Testing\n",
      "- Hypothesis Testing\n",
      "- Customer Rejection Analysis\n",
      "- Feature Tracking\n",
      "- SOP Development\n",
      "- ModelOps\n",
      "- Meta Learners\n",
      "- Propensity Modeling\n",
      "- Offer Management\n",
      "- Google BigQuery\n",
      "- Cloud Platforms (Google Cloud Platform, Azure Databricks)\n",
      "- Version Control (GitHub)\n",
      "- Statistical Analysis\n",
      "- Project Management\n",
      "\n",
      "Experience Summary:\n",
      "- Senior Data Scientist with 5+ years of experience\n",
      "- Worked with Fortune 50 global leaders in BFSI, Retail, and Telecom industries\n",
      "- Proficient in leveraging Advanced Analytics and Artificial Intelligence to provide actionable insights\n",
      "- Experienced in implementing end-to-end data modeling pipelines and solutions using Python, PySpark, and Driverless AI\n",
      "- Expertise in Machine Learning and Deep Learning algorithms\n",
      "- Currently working as a Senior Data Scientist at Etisalate&UAE,\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template = prompt_template, input_variables = [\"text\"])\n",
    "\n",
    "stuff_chain = load_summarize_chain(model,\n",
    "                                   chain_type = \"stuff\",\n",
    "                                   prompt = prompt)\n",
    "\n",
    "output_summary = stuff_chain.run(docs)\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e59d9-1c88-4699-8a9c-2ac573baa625",
   "metadata": {},
   "source": [
    "### Refine Chain\n",
    "\n",
    "#### The Refine documents chain uses an iterative process to generate a response by analyzing each input document and updating its answers accordingly. It passes all non-document inputs, the current document, and the latest intermediate answer to an LLM chain to obtain a new answer for each document. This chain is idea for tasks that involve analyzing more documents than can fit in the models context as it only passes a single document to the LLM at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a32c0f4-ba52-442f-b7ab-a9f21a6e52f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: {existing_answer}\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "{text}\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\n"
     ]
    }
   ],
   "source": [
    "refine_chain = load_summarize_chain(model, chain_type=\"refine\")\n",
    "\n",
    "print(refine_chain.refine_llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ac26205-84e1-4303-990c-adbcc1ff133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Priyanuj Misra is a Senior Data Scientist with 5+ years of experience in Advanced Analytics and Artificial Intelligence. He has worked with Fortune 50 companies in BFSI, Retail, and Telecom industries. His expertise includes end-to-end data modeling using Python, PySpark, and Driverless AI, with a focus on Machine Learning and Deep Learning algorithms. He has experience in developing solutions for tasks such as customer rejection analysis, loan approval prediction, and marketing campaign measurement. Priyanuj holds a MS in Machine Learning and AI from Liverpool John Moores University and a B.Tech in Civil Engineering from NITS. His skills include Python, SQL, Pyspark, Google Cloud Platform, Azure Databricks, and GitHub. He is recognized for his significant impact on improving customer engagement and redemption rates through his propensity model.\n"
     ]
    }
   ],
   "source": [
    "output_summary = refine_chain.run(docs)\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702c171-8f21-4701-8df9-bb36b795d36d",
   "metadata": {},
   "source": [
    "### Map-Reduce Chain\n",
    "#### Again used when there is a lot of documents\n",
    "#### Refine Chain is sequential whereas map reduce is parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52353be9-aebc-424e-88fc-522796184932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a concise summary of the following:\n",
      "\n",
      "\n",
      "\"{text}\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "map_reduce_chain = load_summarize_chain(model, chain_type=\"map_reduce\", verbose = True)\n",
    "\n",
    "print(map_reduce_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c68c7978-5da0-4dba-9359-1c1943840cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"PriyanujMisra\n",
      "Senior Data Scientist\n",
      "Dubai,UAE\n",
      " GitHub\n",
      " LinkedIn\n",
      " priyanujmisra.nits@gmail.com\n",
      " +971506138031\n",
      "PROFESSIONALSUMMARY\n",
      "Senior Data Scientist with 5+ years of experience in leveraging Advanced Analytics and Artificial Intelligence to provide ac-\n",
      "tionable insights for Fortune 50 global leaders in BFSI, Retail and Telecom industries. Proficient in implementing end-to-end\n",
      "data modeling pipelines and solutions using Python, PySpark, and Driverless AI, with expertise in Machine Learning and Deep\n",
      "Learning algorithms.\n",
      "EXPERIENCE\n",
      "Etisalate&UAE | SENIOR DATA SCIENTIST\n",
      "Aug2024–Present|Dubai,UAE\n",
      "Ô Roles and Responsibilities - Part of the CVM Modeling team delivering Machine\n",
      "Learning and Generative AI solutions to optimize business needs and drive\n",
      "revenue. Currently working on preparing a SOP for Information Retrieval using Gen\n",
      "AI (LLM)\n",
      "Ô Customer Rejection Reason Analysis - Developed a Topic Modeling Pipeline\n",
      "using Latent Dirichlet Allocation (LDA) to systematically segment and analyze\n",
      "customer rejection reasons, providing actionable insights to enhance product\n",
      "offerings and reduce rejection rates\n",
      "WellsFargo | SENIOR DATA SCIENTIST\n",
      "June,2021–July,2024|Bangalore,India\n",
      "Ô Loan Approval Date Prediction and Task Prioritization - Developed and deployed\n",
      "a 5-model XGBoost Regression pipeline within the ModelOps framework,\n",
      "enhancing prediction accuracy for Home Lending loans while reducing cycle time\n",
      "by 18% and generating $3.5 million in operational savings\n",
      "Ô Causal Impact Analysis for Marketing Conversations - Led the development of a\n",
      "process utilizing Pyspark and H2O to assess the causality of Marketing\n",
      "Conversations on revenue targets, employing advanced methodologies like\n",
      "Coarsened Exact Matching to establish comparable groups. Utilized Meta\n",
      "Learners to derive ATT/ATEvalues, resulting in an annual profit value of $12.23\n",
      "per customer\n",
      "Ô Feature Tracker Automation - Developed a feature tracking pipeline to monitor\n",
      "3,000+ features weekly, generating ad-hoc summary reports with critical\n",
      "information including summary statistics and Population Stability Index (PSI)\n",
      "MuSigma | DATA SCIENTIST\n",
      "May,2019–June,2021|Bangalore,India\n",
      "Ô Propensity Modeling to enhance Customer Online Engagement - Engineered a\n",
      "Python-based propensity modeling pipeline with a RandomForest classifier to\n",
      "optimize online offers, achieving a fourfold improvement in redemption rate and\n",
      "accelerating customer engagement through seamless integration into the Offer\n",
      "Management system\n",
      "Ô Campaign Design and Management - Designed and implemented an automated\n",
      "capability system in Google BigQuery to distribute personalized offers to over 3\n",
      "Million loyalty customers, yielding pilot campaigns with a projected 30%\n",
      "incremental Year-over-Yearsign-ups and a 5-7% lift in loyalty customer sales\n",
      "Ô Marketing Campaign Measurement - Led the design and implementation of\n",
      "promotional campaigns for MVP experience offers post National Launch,\n",
      "conducting comprehensive Pre-Post analysis on Test and Control segments to\n",
      "optimize campaign effectiveness\n",
      "EDUCATION\n",
      "LIVERPOOLJOHNMOORES\n",
      "UNIVERSITY\n",
      "MS - Machine Learning and AI\n",
      "Aug 2024 - Present | Ongoing\n",
      "Upgrad(Online)\n",
      "NATIONALINSTITUTEOF\n",
      "TECHNOLOGYSILCHAR\n",
      "(NITS)\n",
      "B.Tech - Civil Engineering\n",
      "July, 2015 - May, 2019\n",
      "Silchar,Assam,India\n",
      "SKILLS\n",
      "PROGRAMMING|TOOLS\n",
      "• Python • SQL • Pyspark •\n",
      "Google Cloud Platform • Azure\n",
      "Databricks • GitHub • OSDS •\n",
      "H2O • Jupyter • DataRobot\n",
      "CORECOMPETENCIES\n",
      "• Machine Learning • Deep\n",
      "Learning • Classification •\n",
      "Regression • Random Forest •\n",
      "Boosting Algorithm • NLP •\n",
      "Transformers • Causal\n",
      "Inference • Word Embeddings\n",
      "• Large Language Models •\n",
      "Customer Analytics •\n",
      "Campaign Analytics •\n",
      "Generative AI • Langchain •\n",
      "A/B Testing • Hypothesis\n",
      "Testing • LlamaIndex\n",
      "RECOGNITION\n",
      "SPOTAWARD\n",
      "Citation - Created significant\n",
      "impact by building a propensity\n",
      "model for customer\n",
      "engagement which in turn\n",
      "improved redemption rate\n",
      "fourfold\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" Priyanuj Misra is a Senior Data Scientist with 5+ years of experience in Advanced Analytics and Artificial Intelligence. He has worked with Fortune 50 companies in BFSI, Retail, and Telecom industries. He is skilled in Python, PySpark, and Driverless AI and has expertise in Machine Learning and Deep Learning algorithms. He has experience in developing and deploying data modeling pipelines and solutions. He has worked at Etisalate&UAE, WellsFargo, and MuSigma, where he has led projects in customer rejection analysis, loan approval prediction, marketing impact analysis, and campaign design and management. He is currently pursuing a MS in Machine Learning and AI from Liverpool John Moores University and has a B.Tech in Civil Engineering from NIT Silchar. He is proficient in programming and tools such as Python, SQL, Pyspark, and Google Cloud Platform. His core competencies include Machine Learning, Deep Learning, NLP, and customer and campaign analytics. He has received a Spot Award for his work in building a propensity model for customer engagement. \"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Priyanuj Misra is an experienced Senior Data Scientist with expertise in Advanced Analytics and Artificial Intelligence. He has worked with Fortune 50 companies in various industries and is skilled in Python, PySpark, and Driverless AI. His experience includes developing and deploying data modeling pipelines and solutions, and he is currently pursuing a MS in Machine Learning and AI. He has a B.Tech in Civil Engineering and is proficient in programming and tools such as Python, SQL, Pyspark, and Google Cloud Platform. His core competencies include Machine Learning, Deep Learning, NLP, and customer and campaign analytics. He has received recognition for his work in building a propensity model for customer engagement.\n"
     ]
    }
   ],
   "source": [
    "output_summary = map_reduce_chain.run(docs)\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365a915-47e5-4cc4-abe2-49df52248667",
   "metadata": {},
   "source": [
    "### To visually understand more on the difference between them, upload a document which has more than one page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
